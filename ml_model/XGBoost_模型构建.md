# XGBoost 模型构建

## 3.3 数据处理流程

### 3.3.1 数据加载与预处理

1. **时间范围过滤**：根据配置的 `fit_start_time` 和 `fit_end_time` 参数，过滤出用于特征拟合的数据范围。为确保测试集数据完整性，系统会自动检查并扩展 `fit_end_time` 至测试集结束时间。

## 3.4 特征工程方法

### 3.4.1 滑动窗口特征构建

本研究采用**滑动窗口（Sliding Window）**方法构建监督学习数据集。具体过程如下：

1. **回看窗口（Lookback Window）**：设置 `lookback=30`，表示使用过去 30 个时间步的特征作为输入。

2. **预测窗口（Horizon）**：设置 `horizon=5`，表示预测未来第 5 天的目标值。

3. **特征向量构建**：对于时间点 $t$，将过去 `lookback` 个时间步的所有特征展平为一个一维特征向量：

$$
\mathbf{X}_t = [\mathbf{x}_{t-\text{lookback}}, \mathbf{x}_{t-\text{lookback}+1}, \ldots, \mathbf{x}_{t-1}] \in \mathbb{R}^{6 \times \text{lookback}}
$$

其中，$\mathbf{x}_i \in \mathbb{R}^6$ 表示第 $i$ 个时间步的六个特征值（开盘价、最高价、最低价、收盘价、成交量、成交额）。

4. **标签构建**：对应的标签为未来 `horizon` 天后的目标值：

$$
\mathbf{y}_t = \mathbf{x}_{t+\text{horizon}-1} \in \mathbb{R}^6
$$

### 3.4.2 特征和目标变量

**特征变量**（输入）：
- `open`: 开盘价
- `high`: 最高价
- `low`: 最低价
- `close`: 收盘价
- `volume`: 成交量
- `amount`: 成交额

**目标变量**（输出）：
- 与特征变量相同，预测未来 `horizon` 天后的六个变量值

## 3.5 模型训练过程

### 3.5.1 训练流程

模型训练过程包括以下步骤：

1. ✅**逐列训练**：对每个目标变量（共 6 个），分别训练一个 XGBRegressor 模型。

2. ✅**早停机制**：在训练过程中，使用验证集监控模型性能，通过 `eval_set` 参数同时评估训练集和验证集的 RMSE。

3. ✅**损失曲线记录**：记录每个 boosting round 的训练集和验证集 RMSE，用于分析模型收敛情况和过拟合风险。

4. **模型评估**：训练完成后，在训练集、验证集和测试集上分别计算以下评估指标：
   - **RMSE** (Root Mean Squared Error)：均方根误差
   - **MAE** (Mean Absolute Error)：平均绝对误差
   - **R²** (Coefficient of Determination)：决定系数

5. **结果保存**：
   - ✅保存训练好的模型（pickle 格式）
   - ✅保存预测结果（CSV 格式）
   - ✅保存可视化图表（PNG 格式）
   - 保存评估指标日志（TXT 格式）
   - ✅保存训练/验证损失曲线图



## 3.6 XGBoost 算法优势

XGBoost 算法在时间序列预测任务中具有以下显著优势：

### 3.6.1 强大的非线性建模能力

XGBoost 基于决策树集成，能够自动捕捉特征之间的复杂非线性关系和交互作用，无需人工设计特征交互项。对于金融时间序列数据中存在的非线性模式（如价格波动、成交量变化等），XGBoost 能够有效建模。

### 3.6.2 特征重要性分析

XGBoost 提供了特征重要性评估机制，可以量化每个特征对预测结果的贡献度，有助于理解模型决策过程和特征选择。

### 3.6.3 正则化机制防止过拟合

XGBoost 内置了多种正则化技术：
- **L1 和 L2 正则化**：控制模型复杂度
- **列采样** (`colsample_bytree`)：随机选择部分特征进行训练，增加模型泛化能力
- **行采样** (`subsample`)：随机选择部分样本进行训练，减少过拟合风险

### 3.6.4 处理缺失值和异常值

XGBoost 能够自动处理缺失值，无需额外的数据预处理步骤。同时，通过梯度提升的鲁棒性，对异常值具有一定的抗干扰能力。

### 3.6.5 计算效率高

XGBoost 采用并行计算和优化的数据结构（如稀疏矩阵），训练速度快，支持大规模数据集。通过设置 `nthread` 参数，可以利用多核 CPU 加速训练过程。

### 3.6.6 灵活的预测任务适配

通过逐列训练策略，XGBoost 可以灵活处理多输出回归任务，每个目标变量都有独立的模型，避免了多输出模型可能存在的参数共享问题。

### 3.6.7 可解释性

相比深度学习模型，XGBoost 模型具有更好的可解释性。可以通过可视化决策树、特征重要性等方式理解模型的预测逻辑，这对于金融领域的应用具有重要意义。

## 3.7 模型配置管理

本研究采用 **Hydra** 框架进行配置管理，支持通过 YAML 配置文件统一管理模型超参数、数据路径、输出目录等配置项。同时，支持通过命令行参数动态覆盖配置，提高了实验的灵活性和可重复性。

## 3.8 实验设置

- **回看窗口大小** (`lookback`): 10 天
- **预测窗口大小** (`horizon`): 1天
- **评估指标**: RMSE（均方根误差）
- **模型保存**: 不同 `horizon` 值的模型保存在独立目录中，便于对比分析

